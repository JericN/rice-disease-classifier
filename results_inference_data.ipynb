{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQMPmtYsc63aEuuq+YhvOz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JericN/rice-disease-classifier/blob/main/results_inference_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quite -U fvcore"
      ],
      "metadata": {
        "id": "UUKGlOKk7JLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "import torch\n",
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ],
      "metadata": {
        "id": "wefHsh19vf60"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fvcore.nn import FlopCountAnalysis\n",
        "from fvcore.nn import ActivationCountAnalysis"
      ],
      "metadata": {
        "id": "MYZ8meYG8kr0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"SodaXII/vit-base-patch16-224_rice-leaf-disease-augmented-v4_v5_fft\"\n",
        "# model_name = \"SodaXII/mobilevit-small_rice-leaf-disease-augmented-v4_v5_fft\"\n",
        "# model_name = \"SodaXII/efficientformer_l1.snap_dist_in1k_rice-leaf-disease-augmented-v4_v5_fft\"\n",
        "model_name = \"SodaXII/deit-base-patch16-224_rice-leaf-disease-augmented-v4_v5_fft\"\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(model_name).to(\"cuda\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mpoMGb2RvOJ2",
        "outputId": "14a0e020-93aa-46e3-df30-b7c06e9a4354"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViTForImageClassification(\n",
              "  (vit): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTAttention(\n",
              "            (attention): ViTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 3, 224, 224).to(\"cuda\")  # Adjust input size as needed\n",
        "\n",
        "with profile(\n",
        "    activities=[ProfilerActivity.CUDA],\n",
        "    with_flops=True,\n",
        "    profile_memory=True,\n",
        ") as prof:\n",
        "  with record_function(\"model_inference\"):\n",
        "    model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCHWom8TvSSp",
        "outputId": "caf494dc-194a-44e7-8a84-2fa521eb0f40"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      18.748ms        83.02%      18.748ms     260.382us           0 b           0 b            72  \n",
            "fmha_cutlassF_f32_aligned_64x64_rf_sm75(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us       2.287ms        10.13%       2.287ms     190.567us           0 b           0 b            12  \n",
            "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     366.072us         1.62%     366.072us      14.643us           0 b           0 b            25  \n",
            "_5x_cudnn_volta_scudnn_128x64_relu_xregs_large_nn_v1...         0.00%       0.000us         0.00%       0.000us       0.000us     359.032us         1.59%     359.032us     359.032us           0 b           0 b             1  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     325.880us         1.44%     325.880us       9.052us           0 b           0 b            36  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     204.892us         0.91%     204.892us      17.074us           0 b           0 b            12  \n",
            "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     155.899us         0.69%     155.899us       6.236us           0 b           0 b            25  \n",
            "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us      96.766us         0.43%      96.766us       1.344us           0 b           0 b            72  \n",
            "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      18.944us         0.08%      18.944us      18.944us           0 b           0 b             1  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.968us         0.04%       7.968us       7.968us           0 b           0 b             1  \n",
            "void dot_kernel<float, 128, 0, cublasDotParams<cubla...         0.00%       0.000us         0.00%       0.000us       0.000us       4.768us         0.02%       4.768us       4.768us           0 b           0 b             1  \n",
            "void reduce_1Block_kernel<float, 128, 7, cublasGemvT...         0.00%       0.000us         0.00%       0.000us       0.000us       4.320us         0.02%       4.320us       4.320us           0 b           0 b             1  \n",
            "void cask__5x_cudnn::computeOffsetsKernel<false, fal...         0.00%       0.000us         0.00%       0.000us       0.000us       3.680us         0.02%       3.680us       3.680us           0 b           0 b             1  \n",
            "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           690  \n",
            "                                        cudaEventRecord         0.07%       8.284us         0.07%       8.284us       8.284us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
            "                                  cudaStreamIsCapturing         0.14%      16.841us         0.14%      16.841us       1.295us       0.000us         0.00%       0.000us       0.000us           0 b           0 b            13  \n",
            "                                  cudaStreamGetPriority         0.01%       1.351us         0.01%       1.351us       1.351us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
            "                       cudaDeviceGetStreamPriorityRange         0.01%       1.543us         0.01%       1.543us       1.543us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
            "                                       cudaLaunchKernel        19.43%       2.369ms        19.43%       2.369ms      12.603us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           188  \n",
            "                                    cudaPeekAtLastError         0.01%       1.199us         0.01%       1.199us       0.600us       0.000us         0.00%       0.000us       0.000us           0 b           0 b             2  \n",
            "                                        cudaMemsetAsync         4.24%     517.137us         4.24%     517.137us       7.084us       0.000us         0.00%       0.000us       0.000us           0 b           0 b            73  \n",
            "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.78%      95.316us         0.78%      95.316us       1.324us       0.000us         0.00%       0.000us       0.000us           0 b           0 b            72  \n",
            "                                  cudaDeviceSynchronize        75.30%       9.181ms        75.30%       9.181ms       9.181ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 12.192ms\n",
            "Self CUDA time total: 22.583ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 3, 224, 224).to(\"cuda\")  # Adjust input size as needed\n",
        "\n",
        "# Perform a forward pass to collect activation counts\n",
        "activation_counts = ActivationCountAnalysis(model, inputs)\n",
        "\n",
        "# Perform a forward pass to collect FLOP counts\n",
        "flop_counts = FlopCountAnalysis(model, inputs)\n",
        "\n",
        "# Print the results\n",
        "print(\"Activation Counts:\", activation_counts.total())\n",
        "print(\"FLOP Counts:\", flop_counts.total())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbzbLYyQ7nnq",
        "outputId": "19fbfe83-2a97-4be7-a78f-854550fb60d7"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::batch_norm encountered 33 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::avg_pool2d encountered 14 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sub encountered 14 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 31 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 32 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::gelu encountered 15 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::layer_norm encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::softmax encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mean encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::div encountered 1 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation Counts: 5526040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::avg_pool2d encountered 14 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sub encountered 14 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 31 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 32 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::gelu encountered 15 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::softmax encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mean encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::div encountered 1 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOP Counts: 1301224512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CUDA events for timing\n",
        "start_event = torch.cuda.Event(enable_timing=True)\n",
        "end_event = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "# Load the model and move it to GPU\n",
        "# model_name = \"SodaXII/vit-base-patch16-224_rice-leaf-disease-augmented-v4_v5_fft\"\n",
        "model_name = \"SodaXII/mobilevit-small_rice-leaf-disease-augmented-v4_v5_fft\"\n",
        "# model_name = \"SodaXII/efficientformer_l1.snap_dist_in1k_rice-leaf-disease-augmented-v4_v5_fft\"\n",
        "# model_name = \"SodaXII/deit-base-patch16-224_rice-leaf-disease-augmented-v4_v5_fft\"\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(model_name).to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "# Create a dummy input tensor and move it to GPU\n",
        "input_tensor = torch.randn(1, 3, 224, 224).to(\"cuda\")\n",
        "\n",
        "# # Warm-up runs (optional but recommended)\n",
        "# for _ in range(100):\n",
        "#     with torch.no_grad():\n",
        "#         _ = model(input_tensor)\n",
        "\n",
        "# Reset peak memory statistics before inference\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "\n",
        "\n",
        "# Record the start event\n",
        "start_event.record()\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    _ = model(input_tensor)\n",
        "\n",
        "# Record the end event\n",
        "end_event.record()\n",
        "\n",
        "# Wait for the events to be recorded\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "# Calculate elapsed time in milliseconds\n",
        "inference_time_ms = start_event.elapsed_time(end_event)\n",
        "\n",
        "# Retrieve peak memory usage\n",
        "peak_memory = torch.cuda.max_memory_allocated()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Inference time: {inference_time_ms:.2f} ms\")\n",
        "print(f\"Peak GPU memory usage: {peak_memory / (1024 ** 2):.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7HdNiVv8id7",
        "outputId": "9430b389-7b1e-4896-b49b-df302e76a6b0"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference time: 21.28 ms\n",
            "Peak GPU memory usage: 808.52 MB\n"
          ]
        }
      ]
    }
  ]
}