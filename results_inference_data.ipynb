{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JericN/rice-disease-classifier/blob/main/results_inference_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Drive"
      ],
      "metadata": {
        "id": "_pRaFfv-vSYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "r5WKr3l9vMoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Libraries"
      ],
      "metadata": {
        "id": "u9STWo75vUWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y torch\n",
        "! pip uninstall -y transformers"
      ],
      "metadata": {
        "id": "mPBmI4_q3Vhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quiet tqdm\n",
        "! pip install --quiet -U fvcore\n",
        "! pip install --quiet torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --extra-index-url https://download.pytorch.org/whl/cu124\n",
        "! pip install --quiet transformers==4.48.3"
      ],
      "metadata": {
        "id": "UUKGlOKk7JLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "LCqxdCg_vWtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "from transformers import AutoModelForImageClassification, ViTHybridForImageClassification"
      ],
      "metadata": {
        "id": "MYZ8meYG8kr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Test Config"
      ],
      "metadata": {
        "id": "LCSN_Cg2vaCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the output path in Google Drive\n",
        "root_dir = \"/content/drive/Shareddrives/CS198-Drones/\"\n",
        "output_path = '[TESTv5] Results/model_benchmark.xlsx'\n",
        "\n",
        "# Define the list of model names or paths from Hugging Face\n",
        "model_names = [\n",
        "    \"SodaXII/convnextv2-base-1k-224_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/vit-hybrid-base-bit-384_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/vit-base-patch16-224_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/swin-base-patch4-window7-224_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/deit-base-patch16-224_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/dinov2-base_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "\n",
        "    \"SodaXII/vit_small_patch16_224.augreg_in21k_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/swin-tiny-patch4-window7-224_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/deit-small-patch16-224_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/convnextv2-tiny-1k-224_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "\n",
        "    \"SodaXII/mobilevit-small_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/mobilevitv2_150.cvnets_in22k_ft_in1k_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/efficientnet-b2_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/efficientvit_b1.r224_in1k_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/efficientvit_m4.r224_in1k_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/efficientformerv2_s2.snap_dist_in1k_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "    \"SodaXII/efficientformer_l1.snap_dist_in1k_rice-leaf-disease-augmented-v4_v5_fft\",\n",
        "]\n",
        "\n",
        "# Define batch size and number of iterations\n",
        "batch_size = 32\n",
        "num_iterations = 10"
      ],
      "metadata": {
        "id": "cbzbLYyQ7nnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Model Inference Data"
      ],
      "metadata": {
        "id": "eTZCPo9OvcYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model_name, batch_size, num_iterations):\n",
        "    try:\n",
        "        # Initialize model and move to GPU\n",
        "        ModelClass = ViTHybridForImageClassification if \"hybrid\" in model_name else AutoModelForImageClassification\n",
        "        model = ModelClass.from_pretrained(model_name).to(\"cuda\")\n",
        "        model.eval()\n",
        "\n",
        "        # Create a dummy input tensor with the specified batch size and move it to GPU\n",
        "        if \"hybrid\" in model_name:\n",
        "            input_tensor = torch.randn(batch_size, 3, 384, 384).to(\"cuda\")\n",
        "        else:\n",
        "            input_tensor = torch.randn(batch_size, 3, 224, 224).to(\"cuda\")\n",
        "\n",
        "\n",
        "        # Warm-up iterations\n",
        "        for _ in range(10):\n",
        "            with torch.no_grad():\n",
        "                _ = model(input_tensor)\n",
        "\n",
        "        # Reset peak memory statistics before inference\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        # Create CUDA events for timing\n",
        "        start_event = torch.cuda.Event(enable_timing=True)\n",
        "        end_event = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "        # Record the start event\n",
        "        start_event.record()\n",
        "\n",
        "        # Run inference multiple times\n",
        "        with torch.no_grad():\n",
        "            for _ in range(num_iterations):\n",
        "                _ = model(input_tensor)\n",
        "\n",
        "        # Record the end event\n",
        "        end_event.record()\n",
        "\n",
        "        # Wait for the events to be recorded\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # Calculate average inference time per batch in milliseconds\n",
        "        total_time_ms = start_event.elapsed_time(end_event)\n",
        "        average_inference_time_ms = total_time_ms / num_iterations\n",
        "\n",
        "        # Retrieve peak memory usage\n",
        "        peak_memory = torch.cuda.max_memory_allocated()\n",
        "\n",
        "        # Perform a forward pass to collect FLOP counts\n",
        "        flop_counts = FlopCountAnalysis(model, input_tensor)\n",
        "\n",
        "        # Disable warnings for unsupported operators\n",
        "        flop_counts.unsupported_ops_warnings(False)\n",
        "        flop_counts.uncalled_modules_warnings(False)\n",
        "\n",
        "        total_flops = flop_counts.total()\n",
        "\n",
        "        # Return the evaluation metrics\n",
        "        torch.cuda.empty_cache()\n",
        "        return {\n",
        "            \"Model\": model_name,\n",
        "            \"FLOPs\": total_flops,\n",
        "            \"Average Inference Time (ms)\": average_inference_time_ms,\n",
        "            \"Peak GPU Memory Usage (MB)\": peak_memory / (1024 ** 2)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ An error occurred while evaluating model {model_name}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "MPkPLDWLtwUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Runner Function"
      ],
      "metadata": {
        "id": "wfoZoZ7nvgIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = os.path.join(root_dir, output_path)\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# Iterate over each model and evaluate\n",
        "for model_name in tqdm(model_names, desc=\"Evaluating Models\"):\n",
        "    torch.cuda.empty_cache()\n",
        "    metrics = evaluate_model(model_name, batch_size, num_iterations)\n",
        "    if metrics:\n",
        "        results.append(metrics)\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "df_models = pd.DataFrame(results)\n",
        "\n",
        "# Save the results to an Excel file in Google Drive\n",
        "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "    df_models.to_excel(writer, sheet_name=\"Model Info\", index=False)\n",
        "\n",
        "print(f\"\\n✅ Benchmark results saved to: {output_file}\")"
      ],
      "metadata": {
        "id": "pNUbT7mNt_5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}