{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk6aYXUXhop-"
      },
      "source": [
        "# **Setup and Library Imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkNa8fuxhoqD"
      },
      "source": [
        "### **Connect to google drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8ZgoF0fihoqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d8b81d-328e-4a0a-8272-3118d9f4a1a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foVO8_yXhoqC"
      },
      "source": [
        "### **Logging into Hugging Face Hub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YCeOsgyBhoqD"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "## Execute the login function to access the Hugging Face account\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZjAk0KQhoqA"
      },
      "source": [
        "### **Installing Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jO63oYRzL5Sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b2f7df-9121-4fb4-bd00-4e0b5baa0efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install --quiet \"transformers[torch]\"\n",
        "! pip install --quiet evaluate\n",
        "! pip install --quiet tabulate\n",
        "! pip install --quiet ipywidgets\n",
        "! pip install --quiet datasets\n",
        "! pip install --quiet pillow\n",
        "! pip install --quiet scikit-learn\n",
        "! pip install --quiet tensorboard\n",
        "! pip install --quiet openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWtkX4sJhoqB"
      },
      "source": [
        "### **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VD4j_OeEhoqC"
      },
      "outputs": [],
      "source": [
        "# PyTorch for tensor operations\n",
        "import torch\n",
        "\n",
        "# Hugging Face libraries for training and transformer models\n",
        "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from transformers import AdamW\n",
        "\n",
        "# Evaluation metrics and utilities\n",
        "import os\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Loading datasets for training and evaluation\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Data manipulation and display utilities\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZXEWL3dhoqE"
      },
      "source": [
        "### **Defining Model, Dataset Paths, and Output Directories**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE6mVOWpdhBQ"
      },
      "source": [
        "List of Models\n",
        "\n",
        "\n",
        "```\n",
        "microsoft/resnet-152\n",
        "google/vit-base-patch16-224\n",
        "microsoft/swin-base-patch4-window7-224\n",
        "facebook/deit-base-patch16-224\n",
        "microsoft/beit-base-patch16-224\n",
        "facebook/dinov2-base\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQdE_vIFeGvg"
      },
      "source": [
        "List of Datasets\n",
        "\n",
        "\n",
        "```\n",
        "cvmil/rice-leaf-disease-augmented-v3\n",
        "cvmil/rice-leaf-disease-augmented-v2\n",
        "cvmil/rice-leaf-disease-augmented\n",
        "cvmil/rice-leaf-disease-augmented-test\n",
        "cvmil/rice-disease-02\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgaBaJ0_hoqE"
      },
      "source": [
        "Define paths for saving model training outputs and logs, incorporating model and dataset names along with the current date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oSYVCtcyhoqE"
      },
      "outputs": [],
      "source": [
        "# Define model and dataset paths\n",
        "model_path = \"microsoft/swin-base-patch4-window7-224\"\n",
        "dataset_path = \"cvmil/rice-leaf-disease-augmented-test\"\n",
        "train_epochs = 20\n",
        "resume_from_checkpoint = False\n",
        "\n",
        "base_model_name = model_path.split(\"/\")[-1]\n",
        "dataset_name = dataset_path.split(\"/\")[-1]\n",
        "\n",
        "model_name = f\"{base_model_name}_{dataset_name}_tl\"\n",
        "output_dir = f\"./drive/Shareddrives/CS198-Drones/[v3] Training Output/{model_name}\"\n",
        "\n",
        "# Define directory for storing training logs\n",
        "logging_dir = f\"{output_dir}/logs\"\n",
        "metrics_dir = f\"{output_dir}/training_metrics.xlsx\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BChGCU8hoqF"
      },
      "source": [
        "# **Data Preparation and Processing Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-drvKwRHhoqF"
      },
      "source": [
        "This section handles the dataset loading, label extraction, image processing setup, and defines necessary functions for data transformation, batching, and metric computation to prepare the data for model training and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYKQMYOXhoqF"
      },
      "source": [
        "### **Load Dataset and Extract Labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkTJZsUxhoqF"
      },
      "source": [
        "Load the dataset from huggingface and extract the class labels from the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VpRxa9MghoqG"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(dataset_path)\n",
        "\n",
        "# Extract class labels from the training set\n",
        "labels = dataset['train'].features['label'].names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Uylz9vhoqG"
      },
      "source": [
        "Generate and display a table showing class distribution across training and validation splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OFgqgd9IhoqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd33c65-d043-4fc3-c636-96c773c4cba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------------+------------+--------------+\n",
            "|   ID | Label                  |   Training |   Validation |\n",
            "+======+========================+============+==============+\n",
            "|    0 | Bacterial Leaf Blight  |        100 |           12 |\n",
            "+------+------------------------+------------+--------------+\n",
            "|    1 | Brown Spot             |        100 |           13 |\n",
            "+------+------------------------+------------+--------------+\n",
            "|    2 | Healthy Rice Leaf      |        100 |           12 |\n",
            "+------+------------------------+------------+--------------+\n",
            "|    3 | Leaf Blast             |        100 |           12 |\n",
            "+------+------------------------+------------+--------------+\n",
            "|    4 | Leaf Scald             |        100 |           13 |\n",
            "+------+------------------------+------------+--------------+\n",
            "|    5 | Narrow Brown Leaf Spot |        100 |           13 |\n",
            "+------+------------------------+------------+--------------+\n",
            "|    6 | Rice Hispa             |        100 |           13 |\n",
            "+------+------------------------+------------+--------------+\n",
            "|    7 | Sheath Blight          |        100 |           12 |\n",
            "+------+------------------------+------------+--------------+\n"
          ]
        }
      ],
      "source": [
        "label_mapping = dataset['train'].features['label'].int2str\n",
        "\n",
        "# Count the number of samples per class in each split\n",
        "train_counts = Counter(dataset['train']['label'])\n",
        "validation_counts = Counter(dataset['validation']['label'])\n",
        "\n",
        "# Create a DataFrame for the class distribution\n",
        "data = {\n",
        "    'ID': list(range(len(labels))),\n",
        "    'Label': labels,\n",
        "    'Training': [train_counts[i] if i in train_counts else 0 for i in range(len(labels))],\n",
        "    'Validation': [validation_counts[i] if i in validation_counts else 0 for i in range(len(labels))],\n",
        "}\n",
        "\n",
        "# Display the class distribution in a table format\n",
        "df = pd.DataFrame(data)\n",
        "print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o8mVRnrhoqH"
      },
      "source": [
        "### **Initialize Image Processor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd828v-whoqH"
      },
      "source": [
        "Load and initialize the image processor from the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2jEcfFMjhoqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75fe3eff-be1f-4d82-cb4c-f30c79a866da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViTImageProcessor {\n",
            "  \"do_convert_rgb\": null,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.485,\n",
            "    0.456,\n",
            "    0.406\n",
            "  ],\n",
            "  \"image_processor_type\": \"ViTImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.229,\n",
            "    0.224,\n",
            "    0.225\n",
            "  ],\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"height\": 224,\n",
            "    \"width\": 224\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the image processor from the pre-trained model\n",
        "processor = AutoImageProcessor.from_pretrained(model_path)\n",
        "print(processor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndD-CzRNhoqI"
      },
      "source": [
        "### **Data Preparation and Processing Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcnasYaXhoqI"
      },
      "source": [
        "Create mappings for label-to-ID and ID-to-label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Pts_ZeC4hoqI"
      },
      "outputs": [],
      "source": [
        "label2id = {c: idx for idx, c in enumerate(labels)}\n",
        "id2label = {idx: c for idx, c in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8vi488AhoqJ"
      },
      "source": [
        "Define the transformation function to process the image batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9m7IHmlHhoqJ"
      },
      "outputs": [],
      "source": [
        "def transforms(batch):\n",
        "    batch['image'] = [x.convert('RGB') for x in batch['image']]\n",
        "    inputs = processor(batch['image'], return_tensors='pt')\n",
        "    inputs['labels'] = batch['label']\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fGju_YfhoqJ"
      },
      "source": [
        "Define the custom collation function for batching pixel values and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "obuWgu6UhoqJ"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([x['labels'] for x in batch])\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQf9-A5ChoqJ"
      },
      "source": [
        "Define the function to compute accuracy during evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "441iE0EJhoqJ"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluate.load('accuracy')\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6pLC9gMhoqJ"
      },
      "source": [
        "### **Apply Data Transformations to Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8nsKUHXhoqJ"
      },
      "source": [
        "Apply the defined transformation function to the dataset for preprocessing. </br>\n",
        "Note: This assumes that data augmentation and normalization have already been handled in the previous pipeline and is ready for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JtI5fKF-hoqK"
      },
      "outputs": [],
      "source": [
        "processed_dataset = dataset.with_transform(transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBhs-45QhoqK"
      },
      "source": [
        "# **Model Initialization and Trainer Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGQiqgz4hoqK"
      },
      "source": [
        "This section handles the initialization of the model, configuration of training parameters, and setting up the Trainer for fine-tuning, including the datasets, data processing, and evaluation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwcjXMOShoqK"
      },
      "source": [
        "### **Initialize Pre-trained Model for Fine-tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvdy0OCqhoqK"
      },
      "source": [
        "Load a pre-trained image classification model, configuring it with the correct label mappings and number of labels for the fine-tuning task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oA7vklgChoqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f725c349-4510-4d9b-babb-83fbdcdc99f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 1024]) in the checkpoint and torch.Size([8, 1024]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained model and configure it for fine-tuning\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_path,                  # Path to the pre-trained model\n",
        "    num_labels=len(labels),      # Set the number of labels for classification\n",
        "    id2label=id2label,           # Map from ID to label\n",
        "    label2id=label2id,           # Map from label to ID\n",
        "    ignore_mismatched_sizes=True # Ignore size mismatches in weights\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWoytmixhoqL"
      },
      "source": [
        "### **Check Model Parameters for Fine-tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oxXs4VBhoqL"
      },
      "source": [
        "Freeze the model parameters except for those related to the classifier layers, allowing fine-tuning only on the specified layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4ABaneRjhoqL"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = name.startswith(('classifier', 'distillation_classifier'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZCBbpSghoqL"
      },
      "source": [
        "We can check how many parameters are there in the model along with how many are actually going to be trained now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "utgrV_nghoqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e021a1e-c3ad-403f-bc93-316b27a5d582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 86,751,424 | Trainable parameters: 8,200\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {num_params:,} | Trainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXASOE0whoqL"
      },
      "source": [
        "### **Define Training Arguments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJCDpHAuhoqL"
      },
      "source": [
        "Set up the training configuration with parameters such as batch size, number of epochs, learning rate, and logging strategies for the fine-tuning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "p5qtHrZfhoqL"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=train_epochs,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "\n",
        "    fp16 = True,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    learning_rate=3e-4,\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",\n",
        "    lr_scheduler_kwargs={\"num_cycles\": 4},\n",
        "\n",
        "    save_total_limit=3,\n",
        "    report_to=['tensorboard'],\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    logging_dir=logging_dir,\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    remove_unused_columns=False,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COxN1-tnhHQx"
      },
      "source": [
        "### **Trainer Callback**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "DegSET8xhMfO"
      },
      "outputs": [],
      "source": [
        "class CustomSaveCallback(TrainerCallback):\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        previous_logs = state.log_history[-2:]\n",
        "        new_logs = {k: v for log in previous_logs for k, v in log.items()}\n",
        "\n",
        "        new_logs[\"timestamp\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Add GPU VRAM usage details (in MB)\n",
        "        if torch.cuda.is_available():\n",
        "            new_logs[\"gpu_vram_allocated_mb\"] = torch.cuda.memory_allocated() / (1024 ** 2)\n",
        "            new_logs[\"gpu_vram_reserved_mb\"] = torch.cuda.memory_reserved() / (1024 ** 2)\n",
        "        else:\n",
        "            new_logs[\"gpu_vram_allocated_mb\"] = None\n",
        "            new_logs[\"gpu_vram_reserved_mb\"] = None\n",
        "\n",
        "        # Read the existing Excel file, if it exists\n",
        "        if os.path.exists(metrics_dir):\n",
        "            try:\n",
        "                df_existing = pd.read_excel(metrics_dir)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {metrics_dir}: {e}\")\n",
        "                df_existing = pd.DataFrame()\n",
        "        else:\n",
        "            df_existing = pd.DataFrame()\n",
        "\n",
        "        # Check if this epoch's record already exists; if yes, update it; otherwise, append.\n",
        "        if not df_existing.empty and (df_existing[\"epoch\"] == new_logs[\"epoch\"]).any():\n",
        "            df_existing.loc[df_existing[\"epoch\"] == new_logs[\"epoch\"], new_logs.keys()] = new_logs.values()\n",
        "            df_to_save = df_existing\n",
        "        else:\n",
        "            df_new = pd.DataFrame([new_logs])\n",
        "            df_to_save = pd.concat([df_existing, df_new], ignore_index=True)\n",
        "\n",
        "        # Save the updated DataFrame back to Excel\n",
        "        df_to_save.to_excel(metrics_dir, index=False)\n",
        "        return control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlL9vod3hoqM"
      },
      "source": [
        "### **Initialize Trainer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WIxCidRhoqM"
      },
      "source": [
        "Initialize the Trainer object with the model, training arguments, data collator, metrics computation, and datasets for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4BZs-e_ihoqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f8e854-8e4d-46ed-c8fb-1d1a2b75ca20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-d0e7fb60c29d>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    tokenizer=processor,\n",
        "    callbacks=[CustomSaveCallback()]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QDwYychzRKJ"
      },
      "source": [
        "### **Create Model Card**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "hAAWcGE7zQKG"
      },
      "outputs": [],
      "source": [
        "trainer.create_model_card(\n",
        "    language=\"en\",\n",
        "    license=\"MIT\",\n",
        "    tags=[\"image-classification\", \"fine-tuning\"],\n",
        "    model_name=model_name,\n",
        "    finetuned_from=base_model_name,\n",
        "    tasks=[\"image-classification\"],\n",
        "    dataset_tags=[\"image\", \"rice-leaf-disease\"],\n",
        "    dataset=dataset_name,\n",
        "    dataset_args=[\"size: 224x224\", \"augmentation: true\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKTTEbPnhoqM"
      },
      "source": [
        "# **Model Training and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAJPXDR5hoqM"
      },
      "source": [
        "### **Start Fine-tuning Process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4e3GyJVhoqM"
      },
      "source": [
        "Initiates the fine-tuning of the model using the Trainer, applying the specified training configurations, such as the batch size, learning rate, and number of epochs. During training, the model will be evaluated at the end of each epoch on the validation dataset using the compute_metrics function, which calculates accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcnPa_OdhoqM"
      },
      "source": [
        "The model will undergo the following process during fine-tuning:\n",
        "- **Training**: The model will be trained on the training dataset for the specified number of epochs.\n",
        "- **Evaluation**: After each epoch, the model will be evaluated on the validation dataset, and accuracy will be computed using the compute_metrics function.\n",
        "- **Metrics Logging**: The training progress and evaluation results will be logged to TensorBoard and can be monitored during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UtinFHahoqN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "e6cdbb57-aa4f-4dbf-da71-6423ded1fd33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training swin-base-patch4-window7-224_rice-leaf-disease-augmented-test_tl on rice-leaf-disease-augmented-test dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 80/260 04:52 < 11:14, 0.27 it/s, Epoch 6.08/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.145800</td>\n",
              "      <td>2.080225</td>\n",
              "      <td>0.110000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.993000</td>\n",
              "      <td>1.883896</td>\n",
              "      <td>0.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.766700</td>\n",
              "      <td>1.686860</td>\n",
              "      <td>0.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.583800</td>\n",
              "      <td>1.562095</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.484000</td>\n",
              "      <td>1.505659</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.437600</td>\n",
              "      <td>1.488657</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics for epoch saved\n",
            "Evaluation metrics for epoch saved\n",
            "Evaluation metrics for epoch saved\n",
            "Evaluation metrics for epoch saved\n",
            "Evaluation metrics for epoch saved\n",
            "Evaluation metrics for epoch saved\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training {model_name} on {dataset_name} dataset...\")\n",
        "train_results = trainer.train(resume_from_checkpoint=resume_from_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0rVejNWhoqN"
      },
      "source": [
        "### **Save Model and Training State**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMk4PRTEhoqN"
      },
      "source": [
        "After the training process, the model and relevant training state are saved. This includes saving the model weights, training metrics, and the state of the trainer, ensuring that training progress can be restored if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ePRfHBmhoqN"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "trainer.save_model()\n",
        "\n",
        "# Log and save training metrics for later reference\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "\n",
        "# Save the state of the trainer, including configuration and optimizer state\n",
        "trainer.save_state()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}