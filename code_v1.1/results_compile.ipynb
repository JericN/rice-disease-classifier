{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "1s0_6QDo3yj_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "42yOOYAl3_bD",
        "outputId": "4141d3d4-9b4d-48c1-920a-78db3f0f8429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_dir = \"/content/drive/Shareddrives/CS198-Drones/[v4] FFT Module Evaluation\"\n",
        "results_output_file = \"/content/drive/Shareddrives/CS198-Drones/[v4] FFT Module Evaluation/evaluation.xlsx\"\n",
        "\n",
        "training_dir = \"/content/drive/Shareddrives/CS198-Drones/[v4] Training Output/Full Fine-tune (base)\"\n",
        "training_output_file = \"/content/drive/Shareddrives/CS198-Drones/[v4] Training Output/Full Fine-tune (base)/training_metrics.xlsx\""
      ],
      "metadata": {
        "id": "ekE91V1G35R2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "z8McvzRM1_1v"
      },
      "outputs": [],
      "source": [
        "def compile_evaluation_results(json_folder, output_file):\n",
        "    precision_data = []\n",
        "    recall_data = []\n",
        "    f1_data = []\n",
        "    overall_data = []\n",
        "\n",
        "    for model_dir in os.listdir(json_folder):\n",
        "        model_path = os.path.join(json_folder, model_dir)\n",
        "        json_file_path = os.path.join(model_path, \"report.json\")\n",
        "        if os.path.isdir(model_path) and os.path.isfile(json_file_path):\n",
        "            with open(json_file_path, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                model_name = model_dir\n",
        "\n",
        "                for class_name, metrics in data.items():\n",
        "                    if isinstance(metrics, dict):\n",
        "                        precision_data.append({\"Model\": model_name, \"Class\": class_name, \"Precision\": metrics.get(\"precision\", None)})\n",
        "                        recall_data.append({\"Model\": model_name, \"Class\": class_name, \"Recall\": metrics.get(\"recall\", None)})\n",
        "                        f1_data.append({\"Model\": model_name, \"Class\": class_name, \"F1-Score\": metrics.get(\"f1-score\", None)})\n",
        "\n",
        "                # Add overall data\n",
        "                weighted_ave = data[\"weighted avg\"]\n",
        "                overall_data.append({\"Model\": model_name, \"Accuracy\": data.get(\"accuracy\", None), \"Precision\": weighted_ave.get(\"precision\", None), \"Recall\": weighted_ave.get(\"recall\", None), \"F1-Score\": weighted_ave.get(\"f1-score\", None), \"Support\": weighted_ave.get(\"support\", None), \"Eval Time\": data.get(\"evaluation_time_sec\", None)})\n",
        "\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "        pd.DataFrame(precision_data).pivot(index=\"Model\", columns=\"Class\", values=\"Precision\").to_excel(writer, sheet_name=\"Precision\")\n",
        "        pd.DataFrame(recall_data).pivot(index=\"Model\", columns=\"Class\", values=\"Recall\").to_excel(writer, sheet_name=\"Recall\")\n",
        "        pd.DataFrame(f1_data).pivot(index=\"Model\", columns=\"Class\", values=\"F1-Score\").to_excel(writer, sheet_name=\"F1-Score\")\n",
        "        pd.DataFrame(overall_data).to_excel(writer, sheet_name=\"Overall Accuracy\", index=False)\n",
        "\n",
        "    print(f\"Results saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_training_metrics(metrics_folder, output_file):\n",
        "    # Define metric categories (these will be used as sheet names)\n",
        "    metric_names = [\n",
        "        \"loss\", \"grad_norm\", \"learning_rate\", \"eval_loss\", \"eval_accuracy\",\n",
        "        \"eval_runtime\", \"eval_samples_per_second\", \"eval_steps_per_second\",\n",
        "        \"gpu_vram_allocated_mb\", \"gpu_vram_reserved_mb\"\n",
        "    ]\n",
        "\n",
        "    # Initialize a dictionary to hold DataFrames for each metric\n",
        "    metrics_dict = {metric: pd.DataFrame() for metric in metric_names}\n",
        "\n",
        "    # Loop through model folders\n",
        "    for model_dir in os.listdir(metrics_folder):\n",
        "        model_path = os.path.join(metrics_folder, model_dir)\n",
        "        metrics_file = os.path.join(model_path, \"training_metrics.xlsx\")\n",
        "\n",
        "        if os.path.isdir(model_path) and os.path.isfile(metrics_file):\n",
        "            df = pd.read_excel(metrics_file)\n",
        "\n",
        "            if \"epoch\" not in df.columns:\n",
        "                print(f\"Skipping {model_dir} (No 'epoch' column found)\")\n",
        "                continue\n",
        "\n",
        "            # Ensure epoch is integer and sort\n",
        "            df[\"epoch\"] = df[\"epoch\"]\n",
        "\n",
        "            # Add each metric to its respective dictionary entry\n",
        "            for metric in metric_names:\n",
        "                if metric in df.columns:\n",
        "                    if metrics_dict[metric].empty:\n",
        "                        metrics_dict[metric] = df[[\"epoch\", metric]].copy()\n",
        "                        metrics_dict[metric].rename(columns={metric: model_dir}, inplace=True)\n",
        "                    else:\n",
        "                        metrics_dict[metric] = pd.merge(metrics_dict[metric], df[[\"epoch\", metric]], on=\"epoch\", how=\"outer\")\n",
        "                        metrics_dict[metric].rename(columns={metric: model_dir}, inplace=True)\n",
        "\n",
        "    # Save to Excel\n",
        "    with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
        "        for metric, df in metrics_dict.items():\n",
        "            if not df.empty:\n",
        "                df.to_excel(writer, sheet_name=metric, index=False)\n",
        "\n",
        "    print(f\"Training metrics compiled and saved to {output_file}\")"
      ],
      "metadata": {
        "id": "y_QF1Cvb7rfJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compile_evaluation_results(results_dir, results_output_file)"
      ],
      "metadata": {
        "id": "BgoYe0o64tWr",
        "outputId": "484da8fd-e427-45bf-f6a1-a84e6293a001",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to /content/drive/Shareddrives/CS198-Drones/[v4] FFT Module Evaluation/evaluation.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compile_training_metrics(training_dir, training_output_file)"
      ],
      "metadata": {
        "id": "_HdBKZQQ7uH1",
        "outputId": "7f2d4419-d0c5-4bca-dc05-4873a755a125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training metrics compiled and saved to /content/drive/Shareddrives/CS198-Drones/[v4] Training Output/Full Fine-tune (base)/training_metrics.xlsx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}