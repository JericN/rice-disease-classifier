{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "INXRQeZK7zO2",
      "metadata": {
        "id": "INXRQeZK7zO2",
        "outputId": "9363b5b2-5eb1-4cf3-fc05-43bd2457724a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install --quiet numpy pandas seaborn matplotlib tqdm\n",
        "! pip install --quiet datasets \"transformers[torch]\" scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62d60676",
      "metadata": {
        "id": "62d60676"
      },
      "source": [
        "# Rice Leaf Disease Detection - Model Evaluation\n",
        "This notebook evaluates multiple transformer-based models for rice leaf disease classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a495f82",
      "metadata": {
        "id": "1a495f82"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForImageClassification, AutoProcessor\n",
        "from transformers import ViTHybridForImageClassification, ViTHybridImageProcessor\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97a210a1",
      "metadata": {
        "id": "97a210a1"
      },
      "source": [
        "## Function: Model Evaluation\n",
        "This function loads a pre-trained model and evaluates it on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c54d258",
      "metadata": {
        "id": "6c54d258"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model_name, dataset, labels, batch_size=16, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    \"\"\"Loads a model and evaluates it on the dataset in batches, displaying all failed predictions.\"\"\"\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "\n",
        "    # Load model and processor\n",
        "    if \"hybrid\" in model_name:\n",
        "        model = ViTHybridForImageClassification.from_pretrained(model_name).to(device)\n",
        "        processor = ViTHybridImageProcessor.from_pretrained(model_name)\n",
        "    else:\n",
        "        model = AutoModelForImageClassification.from_pretrained(model_name).to(device)\n",
        "        processor = AutoProcessor.from_pretrained(model_name)\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "    failed_predictions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for example in tqdm(dataset, desc=f\"Testing {model_name}\"):\n",
        "        image, label = example[\"image\"], example[\"label\"]\n",
        "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            pred_label = torch.argmax(outputs.logits, dim=-1).cpu().item()\n",
        "\n",
        "        y_true.append(label)\n",
        "        y_pred.append(pred_label)\n",
        "\n",
        "        if pred_label != label:  # Store failed predictions\n",
        "            failed_predictions.append((image, label, pred_label))\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Model {model_name} evaluation completed in {elapsed_time:.2f} seconds.\")\n",
        "    print(f\"Total failed predictions: {len(failed_predictions)}\")\n",
        "\n",
        "\n",
        "    return y_true, y_pred, failed_predictions, elapsed_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7ddf7e",
      "metadata": {
        "id": "ae7ddf7e"
      },
      "source": [
        "## Function: Generate Report\n",
        "This function generates and saves a classification report and confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb13064c",
      "metadata": {
        "id": "bb13064c"
      },
      "outputs": [],
      "source": [
        "def generate_report(y_true, y_pred, labels, model_name, output_dir, failed_predictions, elapsed_time):\n",
        "    \"\"\"Generates and saves classification report and confusion matrix.\"\"\"\n",
        "    model_safe_name = model_name.split(\"/\")[-1]\n",
        "    model_safe_name = model_safe_name.split(\"_\")[0] + model_safe_name.split(\"_\")[-1]\n",
        "    output_dir = os.path.join(output_dir, model_name.split(\"/\")[-1])\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    report = classification_report(y_true, y_pred, target_names=labels, output_dict=True)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "    report[\"evaluation_time_sec\"] = elapsed_time\n",
        "\n",
        "    # Save JSON report\n",
        "    report_path = os.path.join(output_dir, f\"report.json\")\n",
        "    with open(report_path, \"w\") as f:\n",
        "        json.dump(report, f, indent=4)\n",
        "\n",
        "    # Save Excel report\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    excel_path = os.path.join(output_dir, f\"report.xlsx\")\n",
        "\n",
        "    with pd.ExcelWriter(excel_path) as writer:\n",
        "        report_df.to_excel(writer, sheet_name=\"Classification Report\")\n",
        "        pd.DataFrame(cm, index=labels, columns=labels).to_excel(writer, sheet_name=\"Confusion Matrix\")\n",
        "        pd.DataFrame(cm_normalized, index=labels, columns=labels).to_excel(writer, sheet_name=\"Normalized Confusion Matrix\")\n",
        "\n",
        "    # Display all failed predictions\n",
        "    if failed_predictions:\n",
        "        num_failures = len(failed_predictions)\n",
        "        cols = 4  # Set columns for visualization\n",
        "        rows = (num_failures // cols) + (num_failures % cols > 0)\n",
        "\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(cols * 10, rows * 10))\n",
        "        axes = axes.flatten()  # Flatten for easy iteration\n",
        "\n",
        "        for i, (image, true_label, pred_label) in enumerate(failed_predictions):\n",
        "            ax = axes[i]\n",
        "            ax.imshow(image)  # Assuming images are PIL images\n",
        "            ax.set_title(f\"True: {labels[true_label]}\\nPred: {labels[pred_label]}\")\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        # Hide extra subplots if any\n",
        "        for j in range(i + 1, len(axes)):\n",
        "            axes[j].axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, \"failed_predictions.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    # Save confusion matrix plot\n",
        "    def save_cm_plot(matrix, title, filename, fmt=\"d\"):\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(matrix, annot=True, fmt=fmt, cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "        plt.xlabel(\"Predicted Label\")\n",
        "        plt.ylabel(\"True Label\")\n",
        "        plt.title(title, pad=20)\n",
        "        plt.xticks(rotation=30)\n",
        "        plt.yticks(rotation=30)\n",
        "        plt.savefig(os.path.join(output_dir, filename), bbox_inches=\"tight\", pad_inches=0.3)\n",
        "        plt.close()\n",
        "\n",
        "    save_cm_plot(cm, f\"{model_safe_name} Confusion Matrix\", f\"confusion_matrix.png\")\n",
        "    save_cm_plot(cm_normalized, f\"{model_safe_name} Confusion Matrix\", f\"normalized_confusion_matrix.png\", fmt=\".2f\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_n9x43ydBdBS",
      "metadata": {
        "id": "_n9x43ydBdBS"
      },
      "outputs": [],
      "source": [
        "def save_dataset_info(dataset, output_dir):\n",
        "    info_path = os.path.join(output_dir, \"dataset_info.json\")\n",
        "    # Get class distribution\n",
        "    labels = dataset.features[\"label\"].names\n",
        "    label_counts = {label: 0 for label in labels}\n",
        "\n",
        "    for example in dataset:\n",
        "        label_counts[labels[example[\"label\"]]] += 1\n",
        "\n",
        "    dataset_info = {\n",
        "        \"num_samples\": len(dataset),\n",
        "        \"num_classes\": len(labels),\n",
        "        \"class_distribution\": label_counts,\n",
        "    }\n",
        "\n",
        "    # Save dataset info as JSON\n",
        "    with open(info_path, \"w\") as f:\n",
        "        json.dump(dataset_info, f, indent=4)\n",
        "\n",
        "    # Save class distribution plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=list(label_counts.keys()), y=list(label_counts.values()), palette=\"viridis\")\n",
        "    plt.xticks(rotation=30)\n",
        "    plt.xlabel(\"Classes\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Class Distribution in Test Dataset\")\n",
        "    plt.savefig(os.path.join(output_dir, \"class_distribution.png\"), bbox_inches=\"tight\", pad_inches=0.3)\n",
        "    plt.close()\n",
        "\n",
        "    print(\"✅ Dataset info saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f33636f",
      "metadata": {
        "id": "3f33636f"
      },
      "source": [
        "## Main Function\n",
        "This function loads the dataset, evaluates models, and saves reports to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9774fae5",
      "metadata": {
        "id": "9774fae5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"Mounts Google Drive, loads dataset, evaluates models, and saves reports.\"\"\"\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    models_path = [\n",
        "        \"SodaXII/resnet-152_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/convnextv2-base-1k-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/vit-hybrid-base-bit-384_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/vit-base-patch16-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/swin-base-patch4-window7-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/deit-base-patch16-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/dinov2-base_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/mobilevit-small_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/efficientnet-b0_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/convnextv2-femto-1k-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/vit-tiny-patch16-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/swin-tiny-patch4-window7-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/deit-tiny-patch16-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/resnet-152_rice-leaf-disease-augmented-v4_tl\",\n",
        "        \"SodaXII/convnextv2-base-1k-224_rice-leaf-disease-augmented-v4_tl\",\n",
        "        \"SodaXII/vit-hybrid-base-bit-384_rice-leaf-disease-augmented-v4_tl\",\n",
        "        \"SodaXII/vit-base-patch16-224_rice-leaf-disease-augmented-v4_tl\",\n",
        "        \"SodaXII/swin-base-patch4-window7-224_rice-leaf-disease-augmented-v4_tl\",\n",
        "        \"SodaXII/deit-base-patch16-224_rice-leaf-disease-augmented-v4_tl\",\n",
        "        \"SodaXII/dinov2-base_rice-leaf-disease-augmented-v4_tl\"\n",
        "    ]\n",
        "\n",
        "\n",
        "    dataset = load_dataset(\"cvmil/rice-leaf-disease-augmented-v4\", split=\"test\")\n",
        "    labels = dataset.features[\"label\"].names\n",
        "\n",
        "    output_dir = \"/content/drive/Shareddrives/CS198-Drones/[v4] Model Evaluation/\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    save_dataset_info(dataset, output_dir)\n",
        "\n",
        "    for model_name in models_path:\n",
        "        try:\n",
        "            y_true, y_pred, failed_predictions, elapsed_time = evaluate_model(model_name, dataset, labels)\n",
        "            generate_report(y_true, y_pred, labels, model_name, output_dir, failed_predictions, elapsed_time)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️⚠️⚠️ Error processing {model_name}: {e}\")\n",
        "\n",
        "    print(\"✅ Evaluation completed. Reports saved to Google Drive.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "x-rgjsb-hFq8"
      },
      "id": "x-rgjsb-hFq8"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForImageClassification, AutoProcessor, ViTHybridForImageClassification, ViTHybridImageProcessor\n",
        "from datasets import load_dataset\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "def evaluate_model(model_name, dataset, labels, batch_size=16, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    \"\"\"Loads a model and evaluates it on the dataset, returning predictions and accuracy.\"\"\"\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "\n",
        "    # Load model and processor\n",
        "    if \"hybrid\" in model_name:\n",
        "        model = ViTHybridForImageClassification.from_pretrained(model_name).to(device)\n",
        "        processor = ViTHybridImageProcessor.from_pretrained(model_name)\n",
        "    else:\n",
        "        model = AutoModelForImageClassification.from_pretrained(model_name).to(device)\n",
        "        processor = AutoProcessor.from_pretrained(model_name)\n",
        "\n",
        "    y_true, predictions = [], []\n",
        "\n",
        "    for example in tqdm(dataset, desc=f\"Testing {model_name}\"):\n",
        "        image, label = example[\"image\"], example[\"label\"]\n",
        "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            pred_label = torch.argmax(outputs.logits, dim=-1).cpu().item()\n",
        "\n",
        "        y_true.append(label)\n",
        "        predictions.append(pred_label)\n",
        "\n",
        "    accuracy = accuracy_score(y_true, predictions)\n",
        "    return y_true, predictions, accuracy\n",
        "\n",
        "def ensemble_prediction(models, dataset, labels, output_dir):\n",
        "    \"\"\"Runs multiple models, returns votes, computes accuracy, and saves reports.\"\"\"\n",
        "    all_predictions = {}\n",
        "    model_accuracies = {}\n",
        "    y_true = None\n",
        "\n",
        "    for model_name in models:\n",
        "        try:\n",
        "            y_true, preds, acc = evaluate_model(model_name, dataset, labels)\n",
        "            all_predictions[model_name] = preds\n",
        "            model_accuracies[model_name] = acc\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error processing {model_name}: {e}\")\n",
        "\n",
        "    # Transpose list of lists to get per-sample predictions\n",
        "    per_sample_votes = list(zip(*all_predictions.values()))\n",
        "    final_predictions = [Counter(votes).most_common(1)[0][0] for votes in per_sample_votes]\n",
        "    ensemble_accuracy = accuracy_score(y_true, final_predictions)\n",
        "\n",
        "    # Create a DataFrame with votes per sample, including True Labels\n",
        "    df = pd.DataFrame(per_sample_votes, columns=models, index=[f\"Sample_{i+1}\" for i in range(len(per_sample_votes))])\n",
        "    df.insert(0, \"True Label\", y_true)  # Add True Label as the first column\n",
        "    df[\"Final Prediction\"] = final_predictions\n",
        "    df.to_csv(os.path.join(output_dir, \"ensemble_votes.csv\"))\n",
        "\n",
        "    # Generate model accuracy report\n",
        "    report_data = {\"Model\": list(model_accuracies.keys()) + [\"Ensemble\"],\n",
        "                   \"Accuracy\": list(model_accuracies.values()) + [ensemble_accuracy]}\n",
        "    report_df = pd.DataFrame(report_data)\n",
        "    report_df.to_csv(os.path.join(output_dir, \"model_accuracies.csv\"), index=False)\n",
        "\n",
        "    # Calculate classification report and confusion matrix for ensemble\n",
        "    report = classification_report(y_true, final_predictions, target_names=labels, output_dict=True)\n",
        "    cm = confusion_matrix(y_true, final_predictions)\n",
        "\n",
        "    # Save classification report\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    report_df.to_csv(os.path.join(output_dir, \"classification_report.csv\"))\n",
        "\n",
        "    # Save confusion matrix\n",
        "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    cm_df.to_csv(os.path.join(output_dir, \"confusion_matrix.csv\"))\n",
        "\n",
        "    print(f\"✅ Ensemble vote report saved to {output_dir}/ensemble_votes.csv\")\n",
        "    print(f\"✅ Model accuracies saved to {output_dir}/model_accuracies.csv\")\n",
        "    print(f\"✅ Classification report saved to {output_dir}/classification_report.csv\")\n",
        "    print(f\"✅ Confusion matrix saved to {output_dir}/confusion_matrix.csv\")\n",
        "\n",
        "    return all_predictions\n",
        "\n",
        "def main():\n",
        "    \"\"\"Mounts Google Drive, loads dataset, evaluates models with ensemble method, and saves results.\"\"\"\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    models_path = [\n",
        "        \"SodaXII/mobilevit-small_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/efficientnet-b0_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/convnextv2-femto-1k-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/vit-tiny-patch16-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/swin-tiny-patch4-window7-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "        \"SodaXII/deit-tiny-patch16-224_rice-leaf-disease-augmented-v4_fft\",\n",
        "    ]\n",
        "\n",
        "    dataset = load_dataset(\"cvmil/rice-leaf-disease-augmented-v4\", split=\"test\")\n",
        "    labels = dataset.features[\"label\"].names\n",
        "\n",
        "    output_dir = \"/content/drive/Shareddrives/CS198-Drones/Ensemble_Results\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    all_predictions = ensemble_prediction(models_path, dataset, labels, output_dir)\n",
        "    print(\"✅ Ensemble evaluation completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "d0HYX1e4hFHT",
        "outputId": "e0ea35fb-d806-4887-f8ef-f7d8e4e2fa9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d0HYX1e4hFHT",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Evaluating SodaXII/mobilevit-small_rice-leaf-disease-augmented-v4_fft...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing SodaXII/mobilevit-small_rice-leaf-disease-augmented-v4_fft: 100%|██████████| 298/298 [00:11<00:00, 26.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SodaXII/efficientnet-b0_rice-leaf-disease-augmented-v4_fft...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing SodaXII/efficientnet-b0_rice-leaf-disease-augmented-v4_fft: 100%|██████████| 298/298 [00:07<00:00, 37.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SodaXII/convnextv2-femto-1k-224_rice-leaf-disease-augmented-v4_fft...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing SodaXII/convnextv2-femto-1k-224_rice-leaf-disease-augmented-v4_fft: 100%|██████████| 298/298 [00:11<00:00, 25.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SodaXII/vit-tiny-patch16-224_rice-leaf-disease-augmented-v4_fft...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing SodaXII/vit-tiny-patch16-224_rice-leaf-disease-augmented-v4_fft: 100%|██████████| 298/298 [00:10<00:00, 29.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SodaXII/swin-tiny-patch4-window7-224_rice-leaf-disease-augmented-v4_fft...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing SodaXII/swin-tiny-patch4-window7-224_rice-leaf-disease-augmented-v4_fft: 100%|██████████| 298/298 [00:14<00:00, 20.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SodaXII/deit-tiny-patch16-224_rice-leaf-disease-augmented-v4_fft...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing SodaXII/deit-tiny-patch16-224_rice-leaf-disease-augmented-v4_fft: 100%|██████████| 298/298 [00:10<00:00, 29.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Ensemble vote report saved to /content/drive/Shareddrives/CS198-Drones/Ensemble_Results/ensemble_votes.csv\n",
            "✅ Model accuracies saved to /content/drive/Shareddrives/CS198-Drones/Ensemble_Results/model_accuracies.csv\n",
            "✅ Classification report saved to /content/drive/Shareddrives/CS198-Drones/Ensemble_Results/classification_report.csv\n",
            "✅ Confusion matrix saved to /content/drive/Shareddrives/CS198-Drones/Ensemble_Results/confusion_matrix.csv\n",
            "✅ Ensemble evaluation completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}