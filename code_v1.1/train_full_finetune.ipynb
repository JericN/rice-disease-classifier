{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk6aYXUXhop-"
      },
      "source": [
        "# **Setup and Library Imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkNa8fuxhoqD"
      },
      "source": [
        "### **Connect to google drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZgoF0fihoqE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foVO8_yXhoqC"
      },
      "source": [
        "### **Logging into Hugging Face Hub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCeOsgyBhoqD"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "## Execute the login function to access the Hugging Face account\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZjAk0KQhoqA"
      },
      "source": [
        "### **Installing Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y torch"
      ],
      "metadata": {
        "id": "NcCks-5oLsyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --extra-index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "id": "9ZLwqV-sM_v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO63oYRzL5Sv"
      },
      "outputs": [],
      "source": [
        "! pip install --quiet transformers==4.48.3\n",
        "! pip install --quiet datasets==3.3.2\n",
        "! pip install --quiet evaluate\n",
        "! pip install --quiet tabulate\n",
        "! pip install --quiet ipywidgets\n",
        "! pip install --quiet pillow\n",
        "! pip install --quiet scikit-learn\n",
        "! pip install --quiet tensorboard\n",
        "! pip install --quiet openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWtkX4sJhoqB"
      },
      "source": [
        "### **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD4j_OeEhoqC"
      },
      "outputs": [],
      "source": [
        "# PyTorch for tensor operations\n",
        "import torch\n",
        "\n",
        "# Hugging Face libraries for training and transformer models\n",
        "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "from transformers import AdamW\n",
        "\n",
        "# Evaluation metrics and utilities\n",
        "import os\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Loading datasets for training and evaluation\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Data manipulation and display utilities\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "Q2bwe6xELfpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZXEWL3dhoqE"
      },
      "source": [
        "### **Defining Model, Dataset Paths, and Output Directories**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE6mVOWpdhBQ"
      },
      "source": [
        "List of Models\n",
        "\n",
        "base ~90M\n",
        "```\n",
        "microsoft/resnet-152\n",
        "facebook/convnextv2-base-1k-224\n",
        "google/vit-hybrid-base-bit-384\n",
        "\n",
        "google/vit-base-patch16-224\n",
        "microsoft/swin-base-patch4-window7-224\n",
        "facebook/deit-base-patch16-224\n",
        "facebook/dinov2-base\n",
        "```\n",
        "\n",
        "small ~20M\n",
        "```\n",
        "facebook/convnextv2-tiny-1k-224\n",
        "WinKawaks/vit-small-patch16-224\n",
        "microsoft/swin-tiny-patch4-window7-224\n",
        "facebook/deit-small-patch16-224\n",
        "```\n",
        "\n",
        "tiny ~5M\n",
        "```\n",
        "apple/mobilevit-small\n",
        "google/efficientnet-b0\n",
        "facebook/convnextv2-femto-1k-224\n",
        "WinKawaks/vit-tiny-patch16-224\n",
        "microsoft/swin-tiny-patch4-window7-224\n",
        "facebook/deit-tiny-patch16-224\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQdE_vIFeGvg"
      },
      "source": [
        "List of Datasets\n",
        "\n",
        "\n",
        "```\n",
        "cvmil/rice-leaf-disease-augmented-v4\n",
        "cvmil/rice-leaf-disease-augmented-v3\n",
        "cvmil/rice-leaf-disease-augmented-v2\n",
        "cvmil/rice-leaf-disease-augmented\n",
        "cvmil/rice-leaf-disease-augmented-test\n",
        "cvmil/rice-disease-02\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgaBaJ0_hoqE"
      },
      "source": [
        "Define paths for saving model training outputs and logs, incorporating model and dataset names along with the current date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSYVCtcyhoqE"
      },
      "outputs": [],
      "source": [
        "# Define model and dataset paths\n",
        "model_path = \"\"\n",
        "dataset_path = \"cvmil/rice-leaf-disease-augmented-v4\"\n",
        "train_epochs = 15\n",
        "resume_from_checkpoint = True\n",
        "\n",
        "base_model_name = model_path.split(\"/\")[-1]\n",
        "dataset_name = dataset_path.split(\"/\")[-1]\n",
        "\n",
        "model_name = f\"{base_model_name}_{dataset_name}_fft\"\n",
        "output_dir = f\"./drive/Shareddrives/CS198-Drones/[v4] Training Output/{model_name}\"\n",
        "\n",
        "# Define directory for storing training logs\n",
        "logging_dir = f\"{output_dir}/logs\"\n",
        "metrics_dir = f\"{output_dir}/training_metrics.xlsx\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BChGCU8hoqF"
      },
      "source": [
        "# **Data Preparation and Processing Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-drvKwRHhoqF"
      },
      "source": [
        "This section handles the dataset loading, label extraction, image processing setup, and defines necessary functions for data transformation, batching, and metric computation to prepare the data for model training and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYKQMYOXhoqF"
      },
      "source": [
        "### **Load Dataset and Extract Labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkTJZsUxhoqF"
      },
      "source": [
        "Load the dataset from huggingface and extract the class labels from the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpRxa9MghoqG"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(dataset_path)\n",
        "\n",
        "# Extract class labels from the training set\n",
        "labels = dataset['train'].features['label'].names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0Uylz9vhoqG"
      },
      "source": [
        "Generate and display a table showing class distribution across training and validation splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFgqgd9IhoqG"
      },
      "outputs": [],
      "source": [
        "label_mapping = dataset['train'].features['label'].int2str\n",
        "\n",
        "# Count the number of samples per class in each split\n",
        "train_counts = Counter(dataset['train']['label'])\n",
        "validation_counts = Counter(dataset['validation']['label'])\n",
        "\n",
        "# Create a DataFrame for the class distribution\n",
        "data = {\n",
        "    'ID': list(range(len(labels))),\n",
        "    'Label': labels,\n",
        "    'Training': [train_counts[i] if i in train_counts else 0 for i in range(len(labels))],\n",
        "    'Validation': [validation_counts[i] if i in validation_counts else 0 for i in range(len(labels))],\n",
        "}\n",
        "\n",
        "# Display the class distribution in a table format\n",
        "df = pd.DataFrame(data)\n",
        "print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o8mVRnrhoqH"
      },
      "source": [
        "### **Initialize Image Processor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd828v-whoqH"
      },
      "source": [
        "Load and initialize the image processor from the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jEcfFMjhoqH"
      },
      "outputs": [],
      "source": [
        "# Load the image processor from the pre-trained model\n",
        "processor = AutoImageProcessor.from_pretrained(model_path)\n",
        "print(processor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndD-CzRNhoqI"
      },
      "source": [
        "### **Data Preparation and Processing Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcnasYaXhoqI"
      },
      "source": [
        "Create mappings for label-to-ID and ID-to-label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pts_ZeC4hoqI"
      },
      "outputs": [],
      "source": [
        "label2id = {c: idx for idx, c in enumerate(labels)}\n",
        "id2label = {idx: c for idx, c in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8vi488AhoqJ"
      },
      "source": [
        "Define the transformation function to process the image batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m7IHmlHhoqJ"
      },
      "outputs": [],
      "source": [
        "def transforms(batch):\n",
        "    batch['image'] = [x.convert('RGB') for x in batch['image']]\n",
        "    inputs = processor(batch['image'], return_tensors='pt')\n",
        "    inputs['labels'] = batch['label']\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fGju_YfhoqJ"
      },
      "source": [
        "Define the custom collation function for batching pixel values and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obuWgu6UhoqJ"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([x['labels'] for x in batch])\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQf9-A5ChoqJ"
      },
      "source": [
        "Define the function to compute accuracy during evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "441iE0EJhoqJ"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluate.load('accuracy')\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6pLC9gMhoqJ"
      },
      "source": [
        "### **Apply Data Transformations to Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8nsKUHXhoqJ"
      },
      "source": [
        "Apply the defined transformation function to the dataset for preprocessing. </br>\n",
        "Note: This assumes that data augmentation and normalization have already been handled in the previous pipeline and is ready for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtI5fKF-hoqK"
      },
      "outputs": [],
      "source": [
        "processed_dataset = dataset.with_transform(transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBhs-45QhoqK"
      },
      "source": [
        "# **Model Initialization and Trainer Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGQiqgz4hoqK"
      },
      "source": [
        "This section handles the initialization of the model, configuration of training parameters, and setting up the Trainer for fine-tuning, including the datasets, data processing, and evaluation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwcjXMOShoqK"
      },
      "source": [
        "### **Initialize Pre-trained Model for Fine-tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvdy0OCqhoqK"
      },
      "source": [
        "Load a pre-trained image classification model, configuring it with the correct label mappings and number of labels for the fine-tuning task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA7vklgChoqK"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained model and configure it for fine-tuning\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_path,                  # Path to the pre-trained model\n",
        "    num_labels=len(labels),      # Set the number of labels for classification\n",
        "    id2label=id2label,           # Map from ID to label\n",
        "    label2id=label2id,           # Map from label to ID\n",
        "    ignore_mismatched_sizes=True # Ignore size mismatches in weights\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWoytmixhoqL"
      },
      "source": [
        "### **Check Model Parameters for Fine-tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oxXs4VBhoqL"
      },
      "source": [
        "Unfreeze all layers of the model for full fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ABaneRjhoqL"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZCBbpSghoqL"
      },
      "source": [
        "We can check how many parameters are there in the model along with how many are actually going to be trained now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utgrV_nghoqL"
      },
      "outputs": [],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {num_params:,} | Trainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXASOE0whoqL"
      },
      "source": [
        "### **Define Training Arguments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk0esc5xYIQb"
      },
      "source": [
        "Set learning rate for the model layers, we use lower learning rate for finetuning the pretrained model weight, and higher weight for the classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3iSBlazbMrU"
      },
      "outputs": [],
      "source": [
        "for param in model.named_parameters():\n",
        "    if \"classifier\" in param[0]:\n",
        "        print(param[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciRVFVBGFZBj"
      },
      "source": [
        "### **Create LR Scheduler**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4NIQsDZijTk"
      },
      "outputs": [],
      "source": [
        "# Define different learning rates\n",
        "base_lr = 3e-5\n",
        "classifier_lr = 3e-4\n",
        "weight_decay = 0.1\n",
        "\n",
        "# Separate model parameters\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if \"classifier\" not in n],\n",
        "        \"lr\": base_lr,\n",
        "        \"weight_decay\": weight_decay\n",
        "    },\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if \"classifier\" in n],\n",
        "        \"lr\": classifier_lr,\n",
        "        \"weight_decay\": weight_decay\n",
        "    },\n",
        "]\n",
        "\n",
        "# Define optimizer with different learning rates\n",
        "optimizer = AdamW(optimizer_grouped_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c4pX5k-VbPM"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataset_size = len(processed_dataset[\"train\"])\n",
        "\n",
        "# Calculate steps per epoch\n",
        "steps_per_epoch = max(1, train_dataset_size // batch_size)\n",
        "\n",
        "# Calculate logging steps (2 times per epoch)\n",
        "logging_steps = max(1, steps_per_epoch // 2)\n",
        "\n",
        "# Warmup for 2 epoch\n",
        "warmup_steps =  steps_per_epoch * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJCDpHAuhoqL"
      },
      "source": [
        "Set up the training configuration with parameters such as batch size, number of epochs, learning rate, and logging strategies for the fine-tuning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5qtHrZfhoqL"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=train_epochs,              # Number of training epochs\n",
        "    per_device_train_batch_size=batch_size,     # Batch size for training\n",
        "    per_device_eval_batch_size=batch_size,      # Batch size for evaluation\n",
        "\n",
        "    fp16=True,                                  # Use mixed precision training\n",
        "    warmup_steps=warmup_steps,                  # Warmup step for learning rate scheduler\n",
        "    weight_decay=weight_decay,                  # Weight decay for regularization\n",
        "    lr_scheduler_type='cosine_with_restarts',   # Learning rate scheduler type\n",
        "    lr_scheduler_kwargs = { \"num_cycles\": 3 },  # Number of cycles for learning rate scheduler\n",
        "\n",
        "    save_total_limit=3,                         # Limit the number of saved models\n",
        "    report_to=['tensorboard'],                  # Log to TensorBoard\n",
        "    save_strategy=\"steps\",                      # Save strategy\n",
        "    eval_strategy=\"steps\",                      # Evaluation strategy\n",
        "    logging_strategy=\"steps\",                   # Logging strategy\n",
        "    save_steps=logging_steps,                   # Save steps\n",
        "    eval_steps=logging_steps,                   # Evaluation steps\n",
        "    logging_steps=logging_steps,                # Logging steps\n",
        "    logging_dir=logging_dir,                    # Directory for logging\n",
        "    output_dir=output_dir,                      # Directory for saving outputs\n",
        "\n",
        "    remove_unused_columns=False,                # Retain unused columns in the dataset\n",
        "    load_best_model_at_end=True,                # Load best model at the end of training\n",
        "    metric_for_best_model=\"eval_loss\",          # Specify the metric to track\n",
        "    greater_is_better=False,                    # For loss, lower is better\n",
        "    push_to_hub=True,                           # Push model to Hugging Face Hub\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COxN1-tnhHQx"
      },
      "source": [
        "### **Trainer Callback**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DegSET8xhMfO"
      },
      "outputs": [],
      "source": [
        "class CustomSaveCallback(TrainerCallback):\n",
        "    def __init__(self, trainer):\n",
        "        self.trainer = trainer\n",
        "\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "      drive_id = \"0AND7L-n1cnFpUk9PVA\"\n",
        "      try:\n",
        "          drive_service.files().emptyTrash(driveId=drive_id).execute()\n",
        "      except Exception as e:\n",
        "          print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        previous_logs = state.log_history[-2:]\n",
        "        new_logs = {k: v for log in previous_logs for k, v in log.items()}\n",
        "\n",
        "        new_logs[\"timestamp\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Add GPU VRAM usage details (in MB)\n",
        "        if torch.cuda.is_available():\n",
        "            new_logs[\"gpu_vram_allocated_mb\"] = torch.cuda.memory_allocated() / (1024 ** 2)\n",
        "            new_logs[\"gpu_vram_reserved_mb\"] = torch.cuda.memory_reserved() / (1024 ** 2)\n",
        "        else:\n",
        "            new_logs[\"gpu_vram_allocated_mb\"] = None\n",
        "            new_logs[\"gpu_vram_reserved_mb\"] = None\n",
        "\n",
        "        # Read the existing Excel file, if it exists\n",
        "        if os.path.exists(metrics_dir):\n",
        "            try:\n",
        "                df_existing = pd.read_excel(metrics_dir)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {metrics_dir}: {e}\")\n",
        "                df_existing = pd.DataFrame()\n",
        "        else:\n",
        "            df_existing = pd.DataFrame()\n",
        "\n",
        "        # Check if this epoch's record already exists; if yes, update it; otherwise, append.\n",
        "        if not df_existing.empty and (df_existing[\"epoch\"] == new_logs[\"epoch\"]).any():\n",
        "            df_existing.loc[df_existing[\"epoch\"] == new_logs[\"epoch\"], new_logs.keys()] = new_logs.values()\n",
        "            df_to_save = df_existing\n",
        "        else:\n",
        "            df_new = pd.DataFrame([new_logs])\n",
        "            df_to_save = pd.concat([df_existing, df_new], ignore_index=True)\n",
        "\n",
        "        # Save the updated DataFrame back to Excel\n",
        "        df_to_save.to_excel(metrics_dir, index=False)\n",
        "        return control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlL9vod3hoqM"
      },
      "source": [
        "### **Initialize Trainer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WIxCidRhoqM"
      },
      "source": [
        "Initialize the Trainer object with the model, training arguments, data collator, metrics computation, and datasets for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BZs-e_ihoqM"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collate_fn,\n",
        "    optimizers=(optimizer, None),\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    tokenizer=processor,\n",
        "    callbacks=[CustomSaveCallback(trainer=None)]\n",
        ")\n",
        "\n",
        "# Update callback with trainer instance\n",
        "trainer.callback_handler.callbacks[0].trainer = trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QDwYychzRKJ"
      },
      "source": [
        "### **Create Model Card**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAAWcGE7zQKG"
      },
      "outputs": [],
      "source": [
        "trainer.create_model_card(\n",
        "    language=\"en\",\n",
        "    license=\"MIT\",\n",
        "    tags=[\"image-classification\", \"fine-tuning\"],\n",
        "    model_name=model_name,\n",
        "    finetuned_from=base_model_name,\n",
        "    tasks=[\"image-classification\"],\n",
        "    dataset_tags=[\"image\", \"rice-leaf_disease\"],\n",
        "    dataset=dataset_name,\n",
        "    dataset_args=[\"size: 224x224\", \"augmentation: true\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKTTEbPnhoqM"
      },
      "source": [
        "# **Model Training and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAJPXDR5hoqM"
      },
      "source": [
        "### **Start Fine-tuning Process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4e3GyJVhoqM"
      },
      "source": [
        "Initiates the fine-tuning of the model using the Trainer, applying the specified training configurations, such as the batch size, learning rate, and number of epochs. During training, the model will be evaluated at the end of each epoch on the validation dataset using the compute_metrics function, which calculates accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcnPa_OdhoqM"
      },
      "source": [
        "The model will undergo the following process during fine-tuning:\n",
        "- **Training**: The model will be trained on the training dataset for the specified number of epochs.\n",
        "- **Evaluation**: After each epoch, the model will be evaluated on the validation dataset, and accuracy will be computed using the compute_metrics function.\n",
        "- **Metrics Logging**: The training progress and evaluation results will be logged to TensorBoard and can be monitored during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UtinFHahoqN"
      },
      "outputs": [],
      "source": [
        "print(f\"Training {model_name} on {dataset_name} dataset...\")\n",
        "train_results = trainer.train(resume_from_checkpoint=resume_from_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0rVejNWhoqN"
      },
      "source": [
        "### **Save Model and Training State**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMk4PRTEhoqN"
      },
      "source": [
        "After the training process, the model and relevant training state are saved. This includes saving the model weights, training metrics, and the state of the trainer, ensuring that training progress can be restored if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ePRfHBmhoqN"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "trainer.save_model()\n",
        "\n",
        "# Log and save training metrics for later reference\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "\n",
        "# Save the state of the trainer, including configuration and optimizer state\n",
        "trainer.save_state()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}