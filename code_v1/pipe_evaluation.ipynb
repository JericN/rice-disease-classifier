{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d60676",
   "metadata": {},
   "source": [
    "# Rice Leaf Disease Detection - Model Evaluation\n",
    "This notebook evaluates multiple transformer-based models for rice leaf disease classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a495f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForImageClassification, AutoProcessor\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a210a1",
   "metadata": {},
   "source": [
    "## Function: Model Evaluation\n",
    "This function loads a pre-trained model and evaluates it on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model_name, dataset, labels, batch_size=16, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    \"\"\"Loads a model and evaluates it on the dataset in batches.\"\"\"\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_name).to(device)\n",
    "    processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    all_images, all_labels = [], []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load all images and labels first\n",
    "    for example in tqdm(dataset, desc=f\"Loading {model_name}\"):\n",
    "        all_images.append(example[\"image\"])\n",
    "        all_labels.append(example[\"label\"])\n",
    "\n",
    "    # Process images in batches\n",
    "    for i in tqdm(range(0, len(all_images), batch_size), desc=f\"Testing {model_name}\"):\n",
    "        batch_images = all_images[i:i+batch_size]\n",
    "        batch_labels = all_labels[i:i+batch_size]\n",
    "\n",
    "        inputs = processor(images=batch_images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            batch_preds = torch.argmax(outputs.logits, dim=-1).cpu().tolist()\n",
    "\n",
    "        y_true.extend(batch_labels)\n",
    "        y_pred.extend(batch_preds)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Model {model_name} evaluation completed in {elapsed_time:.2f} seconds.\")\n",
    "    return y_true, y_pred, elapsed_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ddf7e",
   "metadata": {},
   "source": [
    "## Function: Generate Report\n",
    "This function generates and saves a classification report and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_report(y_true, y_pred, labels, model_name, output_dir, elapsed_time):\n",
    "    \"\"\"Generates and saves classification report and confusion matrix.\"\"\"\n",
    "    model_safe_name = model_name.split(\"/\")[-1] + \"-tl\"\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=labels, output_dict=True)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    report[\"evaluation_time_sec\"] = elapsed_time\n",
    "\n",
    "    # Save JSON report\n",
    "    report_path = os.path.join(output_dir, f\"{model_safe_name}_report.json\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "\n",
    "    # Save Excel report\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    excel_path = os.path.join(output_dir, f\"{model_safe_name}_report.xlsx\")\n",
    "\n",
    "    with pd.ExcelWriter(excel_path) as writer:\n",
    "        report_df.to_excel(writer, sheet_name=\"Classification Report\")\n",
    "        pd.DataFrame(cm, index=labels, columns=labels).to_excel(writer, sheet_name=\"Confusion Matrix\")\n",
    "        pd.DataFrame(cm_normalized, index=labels, columns=labels).to_excel(writer, sheet_name=\"Normalized Confusion Matrix\")\n",
    "\n",
    "    # Save confusion matrix plot\n",
    "    def save_cm_plot(matrix, title, filename, fmt=\"d\"):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(matrix, annot=True, fmt=fmt, cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.title(title, pad=20)\n",
    "        plt.xticks(rotation=30)\n",
    "        plt.yticks(rotation=30)\n",
    "        plt.savefig(os.path.join(output_dir, filename), bbox_inches=\"tight\", pad_inches=0.5)\n",
    "        plt.close()\n",
    "\n",
    "    save_cm_plot(cm, f\"{model_safe_name} Confusion Matrix\", f\"{model_safe_name}_confusion_matrix.png\")\n",
    "    save_cm_plot(cm_normalized, \"Normalized Confusion Matrix\", f\"{model_safe_name}_normalized_confusion_matrix.png\", fmt=\".2f\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33636f",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "This function loads the dataset, evaluates models, and saves reports to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Mounts Google Drive, loads dataset, evaluates models, and saves reports.\"\"\"\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    models_path = [\n",
    "        \"cvmil/resnet-50_rice-leaf-disease-augmented_tl\",\n",
    "        \"cvmil/vit-base-patch16-224_rice-leaf-disease-augmented_tl\",\n",
    "        \"cvmil/swin-base-patch4-window7-224_rice-leaf-disease-augmented_tl\",\n",
    "        \"cvmil/deit-base-patch16-224_rice-leaf-disease-augmented_tl\",\n",
    "        \"cvmil/beit-base-patch16-224_rice-leaf-disease-augmented_tl\",\n",
    "        \"cvmil/dinov2-base_rice-leaf-disease-augmented_tl\",\n",
    "    ]\n",
    "\n",
    "    dataset = load_dataset(\"cvmil/rice-leaf-disease-augmented\", split=\"test\")\n",
    "    labels = dataset.features[\"label\"].names\n",
    "\n",
    "    output_dir = \"/content/drive/Shareddrives/CS198-Drones/test_tl_output/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for model_name in models_path:\n",
    "        try:\n",
    "            y_true, y_pred, elapsed_time = evaluate_model(model_name, dataset, labels)\n",
    "            generate_report(y_true, y_pred, labels, model_name, output_dir, elapsed_time)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {model_name}: {e}\")\n",
    "\n",
    "    print(\"✅ Evaluation completed. Reports saved to Google Drive.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
